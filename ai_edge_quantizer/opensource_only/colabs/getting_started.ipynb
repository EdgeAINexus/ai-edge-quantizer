{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z6db789D_hv"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 The AI Edge Quantizer Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsWBIuE3EBCf"
      },
      "outputs": [],
      "source": [
        "!pip install ai-edge-quantizer-nightly\n",
        "!pip install ai-edge-model-explorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD4ZDD9EEE9P"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unHj1x85EHrA"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import model_explorer\n",
        "\n",
        "from ai_edge_quantizer import quantizer\n",
        "from ai_edge_quantizer import recipe\n",
        "from ai_edge_quantizer import qtyping\n",
        "from ai_edge_quantizer.utils import tfl_flatbuffer_utils\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAj-iHUtEQno"
      },
      "source": [
        "## Create and train MNIST in Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpMcV_4-EN3A"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "train_images = train_images.reshape([-1, 28, 28, 1])\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.reshape([-1, 28, 28, 1])\n",
        "\n",
        "num_classes = 10\n",
        "hidden_dim = 32\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Conv2D(\n",
        "        hidden_dim//4,\n",
        "        3,\n",
        "        activation=\"relu\",\n",
        "        padding=\"same\",\n",
        "        input_shape=(28, 28, 1),\n",
        "        use_bias=True,\n",
        "    )\n",
        ")\n",
        "model.add(tf.keras.layers.AveragePooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(hidden_dim, activation=\"relu\", use_bias=True))\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(num_classes, use_bias=False, activation=\"softmax\")\n",
        ")\n",
        "\n",
        "# Train the digit classification model.\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                  from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=5,\n",
        "  validation_data=(test_images, test_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8eYTpZYEdIq"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl3l6Y77Eeqo"
      },
      "outputs": [],
      "source": [
        "def run_tflite_model(tflite_file, test_image_indices):\n",
        "  global test_images\n",
        "\n",
        "  # Initialize the interpreter.\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  print(f\"input details: {input_details}\")\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
        "  for i, test_image_index in enumerate(test_image_indices):\n",
        "    test_image = test_images[test_image_index]\n",
        "\n",
        "    # Check if the input type is quantized, then rescale input data to int8.\n",
        "    if input_details['dtype'] == np.int8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "\n",
        "  return predictions\n",
        "\n",
        "def test_model(tflite_file, test_image_index, model_type):\n",
        "  global test_labels\n",
        "\n",
        "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
        "\n",
        "  plt.imshow(test_images[test_image_index])\n",
        "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
        "  _ = plt.title(template.format(true= str(test_labels[test_image_index]), predict=str(predictions[0])))\n",
        "  plt.grid(False)\n",
        "\n",
        "def evaluate_model(tflite_file, model_type):\n",
        "  global test_images\n",
        "  global test_labels\n",
        "\n",
        "  test_image_indices = range(test_images.shape[0])\n",
        "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
        "\n",
        "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
        "\n",
        "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
        "      model_type, accuracy, len(test_images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBm6JKJaEpjL"
      },
      "source": [
        "## Convert to flatbuffer and visualize float model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulLoMC5TE1Gk"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = \"mnist_model.tflite\"\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "model_explorer.visualize(tflite_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuxtqShHE6-t"
      },
      "source": [
        "## Convert and dynamically quantize with TFL Quantizer and AI Edge Quantizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIMuR0oYFEZm"
      },
      "outputs": [],
      "source": [
        "#@title Convert and dynamically quantize with LiteRT Quantizer\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflq_drq_mnist_model = converter.convert()\n",
        "\n",
        "# Save the dynamically quantized model.\n",
        "tflq_drq_mnist_model_file = \"tflq_drq_mnist_model.tflite\"\n",
        "with open(tflq_drq_mnist_model_file, \"wb\") as f:\n",
        "  f.write(tflq_drq_mnist_model)\n",
        "\n",
        "# NOTE: after TFLQ DRQ only fully_connected node with id = 3 has int8 weights!\n",
        "model_explorer.visualize(tflq_drq_mnist_model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADFOmtTbFKcm"
      },
      "outputs": [],
      "source": [
        "#@title Dynamically quantize with AI Edge Quantizer\n",
        "prefix = \"aeq_drq_mnist_model\"\n",
        "\n",
        "qt = quantizer.Quantizer(tflite_model_file, recipe.dynamic_wi8_afp32())\n",
        "quant_result = qt.quantize().save(\"\", prefix)\n",
        "\n",
        "aeq_drq_mnist_model_file = f\"{prefix}.tflite\"\n",
        "model_explorer.visualize(aeq_drq_mnist_model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByC87y8FTzn"
      },
      "outputs": [],
      "source": [
        "#@title Sanity check of float model on one image\n",
        "\n",
        "# Change this to test a different image.\n",
        "test_image_index = 1\n",
        "\n",
        "# Test the float model\n",
        "test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-NWcuxoF207"
      },
      "outputs": [],
      "source": [
        "#@title Sanity check of TFL DRQ model on one image\n",
        "\n",
        "test_model(tflq_drq_mnist_model_file, test_image_index, model_type=\"TFLQ DRQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yiBEdrQGCx0"
      },
      "outputs": [],
      "source": [
        "#@title Sanity check of AI Edge dynamically quantized model on one image\n",
        "\n",
        "test_model(aeq_drq_mnist_model_file, test_image_index, model_type=\"AEQ dynamically quantized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsSOEtN9GZn2"
      },
      "source": [
        "### Evaluate the models on all images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iqELElvGclH"
      },
      "outputs": [],
      "source": [
        "# Evaluate the float model\n",
        "evaluate_model(tflite_model_file, model_type=\"Float\")\n",
        "\n",
        "# Evaluate the TFL DRQ model\n",
        "evaluate_model(tflq_drq_mnist_model_file, model_type=\"TFLQ DRQ\")\n",
        "\n",
        "# Evaluate the AI Edge dynamically quantized model\n",
        "evaluate_model(aeq_drq_mnist_model_file, model_type=\"AEQ dynamically quantized\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
