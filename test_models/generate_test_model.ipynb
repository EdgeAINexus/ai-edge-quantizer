{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPHEZ40uxT5L"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google3.pyglib import gfile\n",
        "from colabtools import adhoc_import\n",
        "from jax.experimental import jax2tf\n",
        "\n",
        "with adhoc_import.Google3SubmittedChangelist():\n",
        "  from google3.third_party.tensorflow.lite.experimental.mlir.testing.jax.pax import convert_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f3au5JbqIab"
      },
      "outputs": [],
      "source": [
        "def convert_tflite_model(model):\n",
        "  \"\"\"Convert the save TF model to tflite model, then save it as .tflite flatbuffer format\n",
        "\n",
        "  Args:\n",
        "      model (tf.keras.Model): the trained hello_world Model\n",
        "\n",
        "  Returns:\n",
        "      The converted model in serialized format.\n",
        "  \"\"\"\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "  tflite_model = converter.convert()\n",
        "  return tflite_model\n",
        "\n",
        "def write_tfl_model(model, model_path):\n",
        "  with gfile.Open(model_path, 'wb') as f:\n",
        "    f.write(model)\n",
        "  print(f'Wrote to {model_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aon0zxMO21wD"
      },
      "outputs": [],
      "source": [
        "# Convert and save the model to .tflite\n",
        "base_model_path = '/cns/dy-d/home/rewu/quantization_tool/test_models/'\n",
        "gfile.MakeDirs(base_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg2QyhTQpR52"
      },
      "source": [
        "# Single OP Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdeRPOAcpZJP"
      },
      "outputs": [],
      "source": [
        "# @title Fully Connected\n",
        "def create_single_fc_model(hidden_dim=4):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(2,8),batch_size=1))\n",
        "  model.add(\n",
        "      tf.keras.layers.Dense(\n",
        "          hidden_dim,\n",
        "          activation=None,\n",
        "          use_bias=True,\n",
        "          bias_initializer=\"glorot_uniform\",\n",
        "      )\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx4kztHvqXKq"
      },
      "outputs": [],
      "source": [
        "fc_model = create_single_fc_model()\n",
        "tflite_model_float = convert_tflite_model(fc_model)\n",
        "save_path = f'{base_model_path}/single_fc_bias.tflite'\n",
        "write_tfl_model(tflite_model_float, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqa_S8CbRYk7"
      },
      "outputs": [],
      "source": [
        "# @title BMM\n",
        "\n",
        "B, X, Y, Z = 2, 4, 16, 8\n",
        "BMM_WEIGHT1 = np.random.normal(size=(B, Y, Z)).astype(np.float32)\n",
        "BMM_WEIGHT2 = np.random.normal(size=(B, Y, Z)).astype(np.float32)\n",
        "\n",
        "\n",
        "def bmm_test_model(input_tensor):\n",
        "  @tf.function\n",
        "  def tf_bmm(input_tensor):\n",
        "    bmm1 = tf.raw_ops.BatchMatMulV3(\n",
        "        x=input_tensor,\n",
        "        y=BMM_WEIGHT1,  # will recover after conversion\n",
        "        Tout=tf.float32,\n",
        "        adj_y=False,\n",
        "    )\n",
        "    bmm2 = tf.raw_ops.BatchMatMulV3(\n",
        "        x=bmm1,\n",
        "        y=BMM_WEIGHT2,  # will recover after conversion\n",
        "        Tout=tf.float32,\n",
        "        adj_y=True,\n",
        "    )\n",
        "    return bmm2\n",
        "\n",
        "  output = jax2tf.call_tf(tf_bmm)(input_tensor)\n",
        "  return output\n",
        "\n",
        "\n",
        "def convert_bmm(save_path):\n",
        "  input_tf_signature = [\n",
        "      tf.TensorSpec(\n",
        "          (B, X, Y),\n",
        "          tf.float32,\n",
        "          'inputs',\n",
        "      )\n",
        "  ]\n",
        "\n",
        "  def export_func(input_tensor):\n",
        "    return bmm_test_model(input_tensor)\n",
        "\n",
        "  tf_fxn = convert_utils.create_jax2tf_fxn(\n",
        "      export_func, input_tf_signature, use_stablehlo=False\n",
        "  )\n",
        "  tfl_model = convert_utils.convert2tfl(tf_fxn)\n",
        "  write_tfl_model(tfl_model, save_path)\n",
        "\n",
        "\n",
        "save_path = f'{base_model_path}/bmm.tflite'\n",
        "convert_bmm(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmJDihNzG4Jk"
      },
      "outputs": [],
      "source": [
        "# @title embedding_lookup\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "NUM_SELECTIONS = 1\n",
        "NUM_CLASS = 16\n",
        "EMB_VAR = np.random.normal(size=(NUM_CLASS, 8)).astype(np.float32)\n",
        "\n",
        "\n",
        "def embedding_lookup(ids):\n",
        "  one_hot_ids = jax.nn.one_hot(ids, NUM_CLASS)\n",
        "  embs = jnp.einsum('...y,yz-\u003e...z', one_hot_ids, EMB_VAR)\n",
        "  return embs\n",
        "\n",
        "def convert_embedding_lookup(save_path):\n",
        "  input_tf_signature = [\n",
        "      tf.TensorSpec(\n",
        "          (NUM_SELECTIONS,),\n",
        "          tf.int32,\n",
        "          'inputs',\n",
        "      )\n",
        "  ]\n",
        "\n",
        "  def export_func(input_tensor):\n",
        "    return embedding_lookup(input_tensor)\n",
        "\n",
        "  tf_fxn = convert_utils.create_jax2tf_fxn(\n",
        "      export_func, input_tf_signature, use_stablehlo=False\n",
        "  )\n",
        "  tfl_model = convert_utils.convert2tfl(tf_fxn)\n",
        "  write_tfl_model(tfl_model, save_path)\n",
        "\n",
        "save_path = f'{base_model_path}/embedding_lookup.tflite'\n",
        "convert_embedding_lookup(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axI8d_WiINu6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8PD_eIiHqrg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PuE7LumHqod"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiMsF9AB2eQd"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhjGm3tZzReD"
      },
      "outputs": [],
      "source": [
        "# @title test model definition\n",
        "def create_model():\n",
        "  \"\"\"Simple model with conv and fc layers.\"\"\"\n",
        "  num_classes = 10\n",
        "  hidden_dim = 32\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(\n",
        "      tf.keras.layers.Conv2D(\n",
        "          hidden_dim//4,\n",
        "          3,\n",
        "          activation=\"relu\",\n",
        "          padding=\"same\",\n",
        "          input_shape=(28, 28, 1),\n",
        "          use_bias=True,\n",
        "      )\n",
        "  )\n",
        "  model.add(tf.keras.layers.AveragePooling2D())\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(hidden_dim, activation=\"relu\", use_bias=True))\n",
        "  model.add(\n",
        "      tf.keras.layers.Dense(num_classes, use_bias=False, activation=\"softmax\")\n",
        "  )\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"adam\",\n",
        "      loss=\"sparse_categorical_crossentropy\",\n",
        "      metrics=[\"accuracy\"],\n",
        "  )\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL-aR70Y5BrS"
      },
      "outputs": [],
      "source": [
        "# @title train utils\n",
        "def get_data():\n",
        "  \"\"\"Get MNIST train and test data\n",
        "\n",
        "  Returns:\n",
        "      tuple: (data, label) pairs for train and test\n",
        "  \"\"\"\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  x_train = x_train / 255.0  # normalize pixel values to 0-1\n",
        "  x_train = x_train.astype(np.float32)\n",
        "  x_train = x_train.reshape([-1, 28, 28, 1])\n",
        "  return (x_train, y_train)\n",
        "\n",
        "def train_model(epochs, x_values, y_values):\n",
        "  \"\"\"Train keras hello_world model\n",
        "\n",
        "  Args: epochs (int) : number of epochs to train the model\n",
        "      x_train (numpy.array): list of the training data\n",
        "      y_train (numpy.array): list of the corresponding array\n",
        "  Returns:\n",
        "      tf.keras.Model: A trained keras hello_world model\n",
        "  \"\"\"\n",
        "  model = create_model()\n",
        "  model.fit(\n",
        "      x_values,\n",
        "      y_values,\n",
        "      epochs=epochs,\n",
        "      validation_split=0.2,\n",
        "      batch_size=256,\n",
        "      verbose=1,\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02O_5Axbx2hs"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "x_values, y_values = get_data()\n",
        "trained_model = train_model(epochs, x_values, y_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBGux-NCz75b"
      },
      "outputs": [],
      "source": [
        "# Convert and save the model to .tflite\n",
        "tflite_model_float = convert_tflite_model(trained_model)\n",
        "save_path = f'{base_model_path}/conv_fc_mnist.tflite'\n",
        "write_tfl_model(tflite_model_float, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULRhZIuXxQYZ"
      },
      "source": [
        "# Branching model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isuybgCq3OpS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "def create_branching_model():\n",
        "  \"\"\"Create a simple model with branching.\"\"\"\n",
        "  input_layer = layers.Input(\n",
        "      shape=(\n",
        "          4,\n",
        "          4,\n",
        "          1,\n",
        "      ),\n",
        "      batch_size=3,\n",
        "  )\n",
        "  x1, x2, x3 = tf.split(input_layer, 3, axis=0)\n",
        "  # First branch\n",
        "  x1 = tf.reshape(x1, (1, 16))\n",
        "  x1 = tf.keras.layers.Dense(\n",
        "      16, activation=None, use_bias=True, bias_initializer=\"glorot_uniform\"\n",
        "  )(x1)\n",
        "  # Second branch\n",
        "  x2 = layers.Conv2D(\n",
        "      filters=1, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"\n",
        "  )(x2)\n",
        "  x2 = tf.reshape(x2, (1, 16))\n",
        "  # Third branch\n",
        "  x3 = tf.reshape(x3, (1, 16))\n",
        "  # Merge second with third\n",
        "  x2 = tf.concat([x2, x3], axis=0)\n",
        "  # Merge first with the rest\n",
        "  y = tf.concat([x1, x2], axis=0)\n",
        "  y = tf.reshape(y, (48,))\n",
        "  model = Model(inputs=input_layer, outputs=y)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFoLJKPnzVP8"
      },
      "outputs": [],
      "source": [
        "branching_model = create_branching_model()\n",
        "print(branching_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjmJuHTu2K_p"
      },
      "outputs": [],
      "source": [
        "tflite_model_float = convert_tflite_model(branching_model)\n",
        "save_path = f'{base_model_path}/branching_conv_fc.tflite'\n",
        "write_tfl_model(tflite_model_float, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CnKADIH3A5P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/odml/model_customization/quantization/test_models/generate_test_model.ipynb",
          "timestamp": 1715119806868
        },
        {
          "file_id": "/piper/depot/google3/third_party/odml/model_customization/quantization/test_models/generate_test_model.ipynb",
          "timestamp": 1715038673557
        },
        {
          "file_id": "/piper/depot/google3/third_party/odml/model_customization/quantization/test_models/generate_test_model.ipynb",
          "timestamp": 1708971749395
        },
        {
          "file_id": "1V-Fv5rrjL06VnIaEU-6xN0A22OMAIe1W",
          "timestamp": 1707784965711
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
